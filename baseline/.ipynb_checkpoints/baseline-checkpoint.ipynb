{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Language-Modeling\" data-toc-modified-id=\"Language-Modeling-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Language Modeling</a></span></li><li><span><a href=\"#N-grams\" data-toc-modified-id=\"N-grams-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>N-grams</a></span><ul class=\"toc-item\"><li><span><a href=\"#Unigrams\" data-toc-modified-id=\"Unigrams-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Unigrams</a></span></li><li><span><a href=\"#Bigrams\" data-toc-modified-id=\"Bigrams-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Bigrams</a></span></li><li><span><a href=\"#Trigrams\" data-toc-modified-id=\"Trigrams-1.2.3\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>Trigrams</a></span></li></ul></li><li><span><a href=\"#Trigrams-with-linear-interpolation\" data-toc-modified-id=\"Trigrams-with-linear-interpolation-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Trigrams with linear interpolation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Trigrams\" data-toc-modified-id=\"Trigrams-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Trigrams</a></span></li><li><span><a href=\"#Trigrams-with-linear-interpolation\" data-toc-modified-id=\"Trigrams-with-linear-interpolation-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Trigrams with linear interpolation</a></span></li></ul></li>\n",
    "<li><span><a href=\"#Perplexity\" data-toc-modified-id=\"Perplexity-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Perplexity</a></span></li></ul></li>  \n",
    "<li><span><a href=\"#Implementation\" data-toc-modified-id=\"Implementation-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;\n",
    "</span>Implementation</a></span></li><li><span><a href=\"#WikiText-103-dataset-processing\" data-toc-modified-id=\"WikiText-103-dataset-processing-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>WikiText 103 dataset processing</a></span></li><li><span><a href=\"#WikiText-103-Benchmark\" data-toc-modified-id=\"WikiText-103-Benchmark-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>WikiText 103 Benchmark</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un modelo de lenguaje busca calcular la probabilidad de observar una secuancia de tokens o palabras $w_{0}, \\ldots, w_{N}$, usando la regla de la cadena de probabilidades la probabilidad conjunta de observar tal secuencia se descompone en la siguiente expresión\n",
    ":\n",
    "\\begin{equation*}\n",
    "p(w_{0}, \\ldots, w_{N}) = \\prod_{i=0}^{N}p(w_{i}|\\ldots, w_{i-1})\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-grams "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un modelo de N-grams posee una fuerte suposición sobre las probabilidades condicionales de una palabra y su historia ($p(w_{i}|\\ldots, w_{i-1})$), así la probabilidad de obserbar la palabra $w_{i}$ depende de los N-1 palabras anteriores. Por ejemplo:\n",
    "\n",
    "#### Unigrams\n",
    "\\begin{equation*}\n",
    "p(w_{i}|\\ldots, w_{i-1}) = p(w_{i})\n",
    "\\end{equation*}\n",
    "\n",
    "#### Bigrams\n",
    "\\begin{equation*}\n",
    "p(w_{i}|\\ldots, w_{i-1}) = p(w_{i}| w_{i-1})\n",
    "\\end{equation*}\n",
    "\n",
    "#### Trigrams\n",
    "\\begin{equation*}\n",
    "p(w_{i}|\\ldots, w_{i-1}) = p(w_{i}| w_{i-2}, w_{i-1})\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigrams with linear interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El baseline a implementar consiste de un modelo de trigramas con interpolación lineal para evitar el problema de **zero-count**, este problema ocurre cuando la probabilidad de observar un trigrama es cero, lo que trae por consecuencia que la probabilidad conjunta sea cero, pues usando regla de la cadena y markov de segundo orden la probabilidad conjunta se descompone en el producto de los trigramas de la secuencia y basta que un trigrama tenga probabilidad cero para hechar a perder el cálculo de la probabilidad.\n",
    "\n",
    "#### Trigrams\n",
    "\\begin{equation*}\n",
    "p(w_{0}, \\ldots, w_{N}) = \\prod_{i=0}^{N} p(w_{i}| w_{i-2}, w_{i-1})\n",
    "\\end{equation*}\n",
    "\n",
    "#### Trigrams with linear interpolation\n",
    "\n",
    "La probabilidad que entrega este modelo es la combinación convexa de las probabilidades que entregan los modelos unigrams, bigrams y trigrams.\n",
    "\n",
    "\\begin{align}\n",
    "\\nonumber\n",
    "& p(w_{0}, \\ldots, w_{N}) = \\prod_{i=0}^{N}\\lambda_{1} p(w_{i}| w_{i-2}, w_{i-1})+\\lambda_{2} p(w_{i}| w_{i-1})+\\lambda_{3} p(w_{i})\\\\ \\nonumber\n",
    "& \\lambda_{i}\\geq 0, \\; \\lambda_{1}+\\lambda_{2}+\\lambda_{3}=1\\ \\nonumber\n",
    "\\end{align}\n",
    "\n",
    "Los parámetros del modelo se estiman contando casos favorables versus totales, por ejemplo la probabilidad estimada de un trigrama viene dada por la siguiente expresión:\n",
    "\\begin{equation*}\n",
    "q(w_{i}|w_{i-2}, w_{i}) = \\frac{Count(w_{i-2}, w_{i-1}, w_{i})}{Count(w_{i-2}, w_{i-1})}\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "### Perplexity\n",
    "\n",
    "\n",
    "La likelihood de un language model:\n",
    "\n",
    "\\begin{equation*}\n",
    "L = \\prod_{d=1}^{D}p(w_{1}, \\ldots, w_{n_{d}}) = \\prod_{d=1}^{D}\\prod_{i=1}^{n_{d}}p(w_{i}|\\ldots, w_{i-1})\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "Sea $D$ el número de documentos, $n_{d}$ el número de tokens del documento $d$, notar que los documentos son independientes.\n",
    "\n",
    "Luego, la negative log-likelihood:\n",
    "\n",
    "\\begin{equation*}\n",
    "NLL = \\sum_{d=1}^{D}\\sum_{i=1}^{n_{d}}-ln\\big(p(w_{i}|\\ldots, w_{i-1})\\big) = \\sum_{i=1}^{N}-ln\\big(p(w_{i}|\\ldots, w_{i-1})\\big)\n",
    "\\end{equation*}\n",
    "\n",
    "Donde, $N$ es el número de tokens presentes en el corpus.\n",
    "\n",
    "\\begin{equation*}\n",
    "perplexity = e^{\\frac{1}{N}\\times NLL}\n",
    "\\end{equation*}\n",
    "\n",
    "Por tanto, minimizar la perplexity es equivalente a minimizar NLL o maximizar LL.\n",
    "\n",
    "En el caso del modelo de trigramas la perplexity queda:\n",
    "\n",
    "\\begin{equation*}\n",
    "perplexity = exp\\left(\\frac{1}{N}\\sum_{i=1}^{N}-ln\\big(\\lambda_{1} q(w_{i}| w_{i-2}, w_{i-1})+\\lambda_{2} q(w_{i}| w_{i-1})+\\lambda_{3} q(w_{i})\\big)\\right)\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T14:06:07.613631Z",
     "start_time": "2019-10-10T14:06:05.938691Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import nltk\n",
    "#nltk.download('reuters', quiet=True)\n",
    "#nltk.download('punkt', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T14:06:07.619615Z",
     "start_time": "2019-10-10T14:06:07.615626Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import reuters\n",
    "from nltk import bigrams, trigrams\n",
    "from collections import defaultdict\n",
    "from scipy.stats import dirichlet\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T14:06:07.640564Z",
     "start_time": "2019-10-10T14:06:07.622607Z"
    }
   },
   "outputs": [],
   "source": [
    "class Trigrams():     \n",
    "    def fit(self, corpus):\n",
    "        \"\"\"\n",
    "        Ajusta el modelo en el corpus de entrenamiento, guarda los parámetros en atributos.\n",
    "\n",
    "        Parameters:\n",
    "            corpus: {list of str}, shape (corpus_size) \n",
    "            corpus de entrenamiento tokenizado.\n",
    "        Returns:\n",
    "            self: object\n",
    "        \"\"\"\n",
    "        ## Crear diccionarios que guardaran la probabilidad de cada n-gram\n",
    "        model1 = defaultdict(lambda: 0)\n",
    "        model2 = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "        model3 = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "\n",
    "        ## Contar frecuencia de co-ocurrencia\n",
    "        N = len(corpus)\n",
    "        for sentence in corpus:\n",
    "            # Unigrams\n",
    "            model1[None]=N\n",
    "            for w1 in sentence:\n",
    "                model1[w1]+=1\n",
    "            # Bigrams\n",
    "            model2[None][None]=N\n",
    "            for w1, w2 in bigrams(sentence, pad_right=True, pad_left=True):\n",
    "                model2[w1][w2] += 1\n",
    "            # Trigrams\n",
    "            for w1, w2, w3 in trigrams(sentence, pad_right=True, pad_left=True):\n",
    "                model3[(w1, w2)][w3] += 1\n",
    "\n",
    "        ## Transformar conteo a probabilidades\n",
    "        # Trigrams\n",
    "        for w1_w2 in model3:\n",
    "            w1, w2 = w1_w2[0], w1_w2[1]\n",
    "            total_count = model2[w1][w2]\n",
    "            for w3 in model3[w1_w2]:\n",
    "                model3[w1_w2][w3] /= total_count\n",
    "        # Bigrams        \n",
    "        for w1 in model2:\n",
    "            total_count = model1[w1]\n",
    "            for w2 in model2[w1]:\n",
    "                model2[w1][w2] /= total_count\n",
    "        # Unigrams    \n",
    "        total_count = sum(model1.values())\n",
    "        for w1 in model1:\n",
    "            model1[w1] /= total_count\n",
    "\n",
    "        self.model1 = model1\n",
    "        self.model2 = model2\n",
    "        self.model3 = model3     \n",
    "        \n",
    "    def predict_proba_trigam(self, lamb, trigram):\n",
    "        \"\"\"\n",
    "        Calcula la probabilidad de un trigrama usando interpolación lineal.\n",
    "            - p(w3|w1,w2) = lamb_1*q(w3|w1,w2)+lamb_2*q(w3|w2)+lamb_3*q(w3)\n",
    "            - lamb>=0, lamb_1+lamb_2+lamb_3=1\n",
    "        Parameters:\n",
    "            lamb: {array}, shape =3\n",
    "            hiperparámetros del modelo, cada componente debe ser positivo y deben sumar 1.\n",
    "\n",
    "        Returns:\n",
    "            score: float\n",
    "            probabilidad del trigrama\n",
    "        \"\"\"\n",
    "        w1, w2, w3 = trigram\n",
    "        proba = lamb[0]*self.model3[(w1,w2)][w3]+lamb[1]*self.model2[w2][w3]+lamb[2]*self.model1[w3]\n",
    "        return proba\n",
    "        \n",
    "    def get_perplexity(self, lamb, corpus):\n",
    "\n",
    "        \"\"\"\n",
    "        Obtiene la perplexity del modelo en un conjunto de validación\n",
    "            -perplexity = exp(NLL/N), donde NLL es la negative-log-likelihood del modelo y \n",
    "             N el número de trigramas en el corpus.\n",
    "\n",
    "        Parameters:\n",
    "            - corpus: {list of str}, shape (corpus_size) \n",
    "              corpus de validación tokenizado.\n",
    "            - lamb: {array}, shape =3\n",
    "              hiperparámetros del modelo, cada componente debe ser positivo y deben sumar 1.\n",
    "        Returns:\n",
    "            score: float\n",
    "            perplexity\n",
    "        \"\"\"\n",
    "\n",
    "        N = 0 #contador de trigramas del conjunto de validación\n",
    "        NLL = 0 #negative-log-likelihood\n",
    "        for sentence in corpus:\n",
    "            for trigram in trigrams(sentence, pad_right=True, pad_left=True):\n",
    "                trigram_proba = self.predict_proba_trigam(lamb, trigram)\n",
    "                NLL = NLL - np.log(trigram_proba) \n",
    "                N = N+1\n",
    "        perplexity = np.exp(NLL/N)\n",
    "\n",
    "        return perplexity\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T14:06:16.402829Z",
     "start_time": "2019-10-10T14:06:07.644549Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ASIAN', 'EXPORTERS', 'FEAR', 'DAMAGE', 'FROM', 'U', '.', 'S', '.-', 'JAPAN', 'RIFT', 'Mounting', 'trade', 'friction', 'between', 'the', 'U', '.', 'S', '.', 'And', 'Japan', 'has', 'raised', 'fears', 'among', 'many', 'of', 'Asia', \"'\", 's', 'exporting', 'nations', 'that', 'the', 'row', 'could', 'inflict', 'far', '-', 'reaching', 'economic', 'damage', ',', 'businessmen', 'and', 'officials', 'said', '.']\n",
      "54716\n"
     ]
    }
   ],
   "source": [
    "corpus = reuters.sents()\n",
    "print(corpus[0])\n",
    "print(len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T14:06:31.174168Z",
     "start_time": "2019-10-10T14:06:16.404824Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 22.8 s\n"
     ]
    }
   ],
   "source": [
    "model = Trigrams()\n",
    "%time model.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T14:06:46.056056Z",
     "start_time": "2019-10-10T14:06:31.176128Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 23.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.383050732528654"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lamb = [0.7, 0.2, 0.1]\n",
    "%time model.get_perplexity(lamb, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T14:06:46.070018Z",
     "start_time": "2019-10-10T14:06:46.058051Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ASIAN', 'EXPORTERS', 'FEAR')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7043479387228446"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calcular probabilidad de un trigrama\n",
    "example = trigrams(corpus[0], pad_right=True, pad_left=True)\n",
    "example_trigrams = []\n",
    "for trigram in example:\n",
    "    example_trigrams.append(trigram)\n",
    "    \n",
    "print(example_trigrams[2])\n",
    "model.predict_proba_trigam(lamb, example_trigrams[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WikiText 103 dataset processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the files were already tokenize we must build the tokens array for each dataset. Using the spaces left by the tokenization and the file names the three arrays of tokens are built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T14:07:15.513541Z",
     "start_time": "2019-10-10T14:06:46.075005Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraphs on train:      859532\n",
      "Paragraphs on validation: 1841\n",
      "Paragraphs on test:       2183\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "shutil.unpack_archive('../wikitext-103-v1.zip', extract_dir='dataset')\n",
    "working_dir = os.path.join(os.getcwd(), 'dataset', 'wikitext-103')\n",
    "\n",
    "wikitext_files = os.listdir(working_dir)\n",
    "\n",
    "wiki_train = []\n",
    "wiki_train_vocabulary = []\n",
    "wiki_test = []\n",
    "wiki_valid = []\n",
    "\n",
    "for wikitext_file in wikitext_files:\n",
    "    with open(os.path.join(working_dir, wikitext_file), encoding='utf-8') as data_file:\n",
    "        for index, line in enumerate(data_file):\n",
    "            # Filter out empty lines and headers\n",
    "            if len(line) < 3 or line[1] == '=':\n",
    "                continue\n",
    "            else:\n",
    "                if re.match(r'.*\\.train\\..*', wikitext_file):\n",
    "                    wiki_train.append(line.strip().split(' '))\n",
    "                \n",
    "                elif re.match(r'.*\\.test\\..*', wikitext_file):\n",
    "                    wiki_test.append(line.strip().split(' '))\n",
    "                    \n",
    "                elif re.match(r'.*\\.valid\\..*', wikitext_file):\n",
    "                    wiki_valid.append(line.strip().split(' '))\n",
    "                    \n",
    "shutil.rmtree('dataset')\n",
    "                    \n",
    "print(f'Paragraphs on train:      {len(wiki_train)}')\n",
    "print(f'Paragraphs on validation: {len(wiki_valid)}')\n",
    "print(f'Paragraphs on test:       {len(wiki_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T14:08:40.853733Z",
     "start_time": "2019-10-10T14:07:15.515535Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21.9 s\n",
      "Vocabulary has 267631 tokens\n",
      "0 words were out of vocabulary\n",
      "Wall time: 209 ms\n",
      "1 words were out of vocabulary\n",
      "Wall time: 191 ms\n"
     ]
    }
   ],
   "source": [
    "def get_vocabulary(dataset):\n",
    "    vocabulary = set()\n",
    "    for doc in dataset:\n",
    "        set_doc = set(doc)\n",
    "        vocabulary.update(set_doc)\n",
    "    return vocabulary\n",
    "\n",
    "def remove_out_of_vocabulary(vocabulary, dataset):\n",
    "    new_dataset = []\n",
    "    deleted = 0\n",
    "    \n",
    "    vocabulary = set(vocabulary)\n",
    "    \n",
    "    for paragraph in dataset:\n",
    "        new_paragraph = []\n",
    "        inter = set(paragraph) & vocabulary\n",
    "        \n",
    "        for word in paragraph:\n",
    "            if word in inter:\n",
    "                new_paragraph.append(word)\n",
    "            \n",
    "            else:\n",
    "                deleted += 1\n",
    "\n",
    "        new_dataset.append(new_paragraph)\n",
    "\n",
    "    print(f'{deleted} words were out of vocabulary')\n",
    "    return new_dataset\n",
    "\n",
    "%time vocabulary = get_vocabulary(wiki_train)\n",
    "\n",
    "print(f'Vocabulary has {len(vocabulary)} tokens')\n",
    "\n",
    "%time wiki_test = remove_out_of_vocabulary(vocabulary, wiki_test)\n",
    "%time wiki_valid = remove_out_of_vocabulary(vocabulary, wiki_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens in train 99183639, tokens in validation 209337, tokens in test 235845\n"
     ]
    }
   ],
   "source": [
    "tokens_train = np.array([len(doc) for doc in wiki_train]).sum()\n",
    "tokens_valid = np.array([len(doc) for doc in wiki_valid]).sum()\n",
    "tokens_test = np.array([len(doc) for doc in wiki_test]).sum()\n",
    "print(f'Tokens in train {tokens_train}, tokens in validation {tokens_valid}, tokens in test {tokens_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WikiText 103 Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we must train a new model. This process is similar to the one shown in section 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T14:16:35.648966Z",
     "start_time": "2019-10-10T14:08:40.855715Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9min 14s\n"
     ]
    }
   ],
   "source": [
    "wikitext_model = Trigrams()\n",
    "%time wikitext_model.fit(wiki_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185.7205457687378\n"
     ]
    }
   ],
   "source": [
    "ti = time()\n",
    "#A dirichlet sample is a vector where each component is not negative and together sum 1 \n",
    "pdf = dirichlet(alpha = [64, 16, 4]) #ramdom samples tend to satisfy lambda1>lambda2>lambda3\n",
    "lambdas = pdf.rvs(size=100, random_state=0) #sampling 100 samples from dirichlet\n",
    "perplexity = []\n",
    "for i in range(len(lambdas)):\n",
    "    perplexity.append(wikitext_model.get_perplexity(lambdas[i], wiki_valid))\n",
    "tf = time()\n",
    "print(tf-ti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-10T14:06:06.655Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lambda</th>\n",
       "      <th>perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.7530998810534665, 0.1653703938100571, 0.081...</td>\n",
       "      <td>204.750771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.7396865545042431, 0.20093036496452085, 0.05...</td>\n",
       "      <td>202.673851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.7712929451790139, 0.17815126960288025, 0.05...</td>\n",
       "      <td>208.609841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.7212971745490596, 0.24297095143372444, 0.03...</td>\n",
       "      <td>203.396918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.6155053151143111, 0.2494869060497376, 0.135...</td>\n",
       "      <td>190.387655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              lambda  perplexity\n",
       "0  [0.7530998810534665, 0.1653703938100571, 0.081...  204.750771\n",
       "1  [0.7396865545042431, 0.20093036496452085, 0.05...  202.673851\n",
       "2  [0.7712929451790139, 0.17815126960288025, 0.05...  208.609841\n",
       "3  [0.7212971745490596, 0.24297095143372444, 0.03...  203.396918\n",
       "4  [0.6155053151143111, 0.2494869060497376, 0.135...  190.387655"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_scores = pd.DataFrame({'lambda':pd.Series(lambdas.tolist()), 'perplexity':pd.Series(perplexity)})\n",
    "validation_scores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take the configuration with best perplexity (minium) and we run them with the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-10T14:06:06.839Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lambda</th>\n",
       "      <th>perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.6155053151143111, 0.2494869060497376, 0.135...</td>\n",
       "      <td>190.387655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.6389284514853635, 0.27312456407959157, 0.08...</td>\n",
       "      <td>190.826166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>[0.662545908458533, 0.24844956753710032, 0.089...</td>\n",
       "      <td>192.820311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0.693068868830631, 0.23634674049083365, 0.070...</td>\n",
       "      <td>196.164647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>[0.6881357187938214, 0.20199917444681775, 0.10...</td>\n",
       "      <td>196.202703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               lambda  perplexity\n",
       "4   [0.6155053151143111, 0.2494869060497376, 0.135...  190.387655\n",
       "5   [0.6389284514853635, 0.27312456407959157, 0.08...  190.826166\n",
       "95  [0.662545908458533, 0.24844956753710032, 0.089...  192.820311\n",
       "12  [0.693068868830631, 0.23634674049083365, 0.070...  196.164647\n",
       "92  [0.6881357187938214, 0.20199917444681775, 0.10...  196.202703"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_configurations = validation_scores.sort_values('perplexity', ascending=True).head()\n",
    "best_lambda = best_configurations['lambda'].iloc[0]\n",
    "best_configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-10T14:06:06.843Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194.55602341733223"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity_test = wikitext_model.get_perplexity(best_lambda, wiki_test)\n",
    "perplexity_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
