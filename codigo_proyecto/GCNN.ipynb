{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import Sampler\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from gcnn import GCNNmodel\n",
    "from config import params\n",
    "from GCNN_textfuncs import LMDataset_GCNN, SortishSampler_GCNN, SortSampler_GCNN, pad_collate_GCNN\n",
    "from fastai.text import TextLMDataBunch\n",
    "import time\n",
    "import torch.nn as nn\n",
    "\n",
    "from tools import make_paragraphs, make_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs': 50,\n",
       " 'emb_sz': 300,\n",
       " 'k': 4,\n",
       " 'nh': 600,\n",
       " 'nl': 4,\n",
       " 'downbot': 20,\n",
       " 'batch_size': 20,\n",
       " 'lr': 1,\n",
       " 'mom': 0.95,\n",
       " 'wd': 5e-05,\n",
       " 'nesterov': True,\n",
       " 'grad_clip': 0.07,\n",
       " 'opttype': 'sgd',\n",
       " 'use_gpu': True}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPATH = 'data/GCNN/'\n",
    "\n",
    "#Preprocesamiento\n",
    "\n",
    "#Leer data, notar que so ntextos largos\n",
    "df_train = pd.read_csv(DATAPATH+'train.csv',header=None,names=['text'])\n",
    "df_test = pd.read_csv(DATAPATH+'test.csv',header=None,names=['text'])\n",
    "\n",
    "# textos\n",
    "\n",
    "text_train = df_train.text.values\n",
    "test_train = df_test.text.values\n",
    "\n",
    "\n",
    "#Eliminar dataframes de memoria\n",
    "try:\n",
    "    del df_train, df_test\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Se realizan párrafos para el entrenamiento\n",
    "\n",
    "- Se corta el texto por saltos \\n\n",
    "- Se eliminan párrafos con largo menor a min_len y mayor a max_len\n",
    "- Se agrega tag 'EOS' al final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paragraphs = make_paragraphs(text_train)\n",
    "test_paragraphs = make_paragraphs(test_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['= = = = 2011 = = = =EOS',\n",
       " '= = = = 2012 = = = =EOS',\n",
       " '= = = = 2013 = = = =EOS',\n",
       " '= = = = 2015 = = = =EOS',\n",
       " '= = = = 2006 = = = =EOS']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_paragraphs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_par = pd.DataFrame({'text':train_paragraphs})\n",
    "df_test_par = pd.DataFrame({'text':test_paragraphs})\n",
    "\n",
    "#Etiquetas se agregan para cargar datos despues\n",
    "df_train_par['labels'] = 0\n",
    "df_test_par['labels'] = 0\n",
    "\n",
    "df_train_par = df_train_par[['labels','text']]\n",
    "df_test_par = df_test_par[['labels','text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_par.to_csv('train_proc_par2.csv', header=False, index=False)\n",
    "df_test_par.to_csv('test_proc_par2.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17411, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_par.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1864, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_par.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar datos con fastai.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm = TextLMDataBunch.from_csv(path = '', csv_name='train_proc_par2.csv', test='test_proc_par2.csv')\n",
    "itos=data_lm.train_ds.vocab.itos# the vocab\n",
    "vs=len(itos)# vs is the length of the vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens=[data_lm.train_ds[i][0].data for i in range(len(data_lm.train_ds))]\n",
    "test_tokens=[data_lm.valid_ds[i][0].data for i in range(len(data_lm.valid_ds))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = LMDataset_GCNN(train_tokens)\n",
    "test_dataset = LMDataset_GCNN(test_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear DataLoader y Samplers\n",
    "\n",
    "Los siguientes pasos son muy importantes para poder entrenar el modelo.\n",
    "\n",
    "- El Sampler se encarga de generar las muestras de manera correcta en el DataLoader\n",
    "- El DataLoader se encarga de cargar bien los datos para poder manejarlos en memoria\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Samplers\n",
    "train_sampler = SortishSampler_GCNN(data_length = len(train_dataset),key=lambda x:len(train_dataset[x][0]), bs = params['batch_size'])\n",
    "test_sampler = SortSampler_GCNN(test_dataset,key = lambda x:len(test_dataset[x][0]))\n",
    "\n",
    "#DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size = params['batch_size'], collate_fn=pad_collate_GCNN, sampler = train_sampler, pin_memory= False)\n",
    "test_loader = DataLoader(test_dataset, batch_size= params['batch_size'], collate_fn=pad_collate_GCNN, sampler = test_sampler, pin_memory= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import collections\n",
    "\n",
    "def make_embeddings(path, itos, embedding_size):\n",
    "    \"\"\" A partir del path de un .txt con embeddings genera un vector numpy de embeddings\n",
    "    \"\"\"\n",
    "    words = []\n",
    "    word2idx = {}\n",
    "    vectors = []\n",
    "    idx = 0\n",
    "    with open(path, 'rb') as file:\n",
    "        for line in file:\n",
    "            line = line.decode().split()\n",
    "            word = line[0]\n",
    "            words.append(word)\n",
    "            word2idx[word] = idx\n",
    "            idx += 1\n",
    "            vectors.append(line[1:])\n",
    "    \n",
    "    #Verificamos que tengamos misma cantidad de palabras y vectores\n",
    "    assert len(words) == len(vectors)\n",
    "    \n",
    "    #Generamos diccionario\n",
    "    temporal_dictionary = collections.defaultdict(lambda:-1, {v:k for k,v in enumerate(words)})\n",
    "    unk_row = vectors[-1] # vector default para <unk>\n",
    "    #Creamos vector de tamaño número de palabras, por tamaño de embedding\n",
    "    embeddings = np.zeros((len(itos), embedding_size), dtype=np.float32)\n",
    "    \n",
    "    #Vamos iterando por palabras del diccionario que creamos antes para generar vector de embeddings con la misma\n",
    "    #correspondencia de indices\n",
    "    for i, word in enumerate(itos):\n",
    "        index = temporal_dictionary[word] #indice de palabra en diccionario temporal de embeddings cargados\n",
    "        #Generamos el vector de embeddings \n",
    "        embeddings[i] = vectors[index] if index>=0 else unk_row #Si no lo encuentra asigna vector por defecto \n",
    "        \n",
    "    return embeddings\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/GCNN/glove.6B.300d.txt'\n",
    "embeddings = make_embeddings(path, itos, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revisar embeddings\n",
    "\n",
    "- Notemos que el largo del diccionario que creamos es igual al número de filas del vector de embeddings\n",
    "- Se pueden hacer pruebas filtrando más o menos palabras con gensim dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28160, (28160, 300))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(itos), embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('embeddings.npy', embeddings) #Guardar embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "Primero generamos el modelo, los párametros están en config.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCNN = GCNNmodel(vocab_size, params['emb_sz'], params['k'], params['nh'], params['nl'], params['downbot'])\n",
    "#Si se quiere usar GPU hay que poner el modelo en GPU con .cuda()\n",
    "if params['use_gpu']:\n",
    "    GCNN.cuda()\n",
    "    #Setear los embeddings de glove en la capa de embeddings\n",
    "    GCNN.embed.weight.data = torch.FloatTensor(embeddings).cuda()\n",
    "else:\n",
    "    GCNN.model.embed.weight.data = torch.FloatTensor(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCNNmodel(\n",
       "  (embed): Embedding(28160, 300)\n",
       "  (inlayer): GLUblock(\n",
       "    (convresid): Conv2d(300, 600, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (leftpad): ConstantPad2d(padding=(0, 0, 3, 0), value=0)\n",
       "    (convx1a): Conv2d(300, 15, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (convx2a): Conv2d(300, 15, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (convx1b): Conv2d(15, 15, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (convx2b): Conv2d(15, 15, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (convx1c): Conv2d(15, 600, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (convx2c): Conv2d(15, 600, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (GLUlayers): Sequential(\n",
       "    (0): GLUblock(\n",
       "      (convresid): Conv2d(600, 600, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (leftpad): ConstantPad2d(padding=(0, 0, 3, 0), value=0)\n",
       "      (convx1a): Conv2d(600, 30, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (convx2a): Conv2d(600, 30, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (convx1b): Conv2d(30, 30, kernel_size=(4, 1), stride=(1, 1))\n",
       "      (convx2b): Conv2d(30, 30, kernel_size=(4, 1), stride=(1, 1))\n",
       "      (convx1c): Conv2d(30, 600, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (convx2c): Conv2d(30, 600, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (1): GLUblock(\n",
       "      (convresid): Conv2d(600, 600, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (leftpad): ConstantPad2d(padding=(0, 0, 3, 0), value=0)\n",
       "      (convx1a): Conv2d(600, 30, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (convx2a): Conv2d(600, 30, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (convx1b): Conv2d(30, 30, kernel_size=(4, 1), stride=(1, 1))\n",
       "      (convx2b): Conv2d(30, 30, kernel_size=(4, 1), stride=(1, 1))\n",
       "      (convx1c): Conv2d(30, 600, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (convx2c): Conv2d(30, 600, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (2): GLUblock(\n",
       "      (convresid): Conv2d(600, 600, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (leftpad): ConstantPad2d(padding=(0, 0, 3, 0), value=0)\n",
       "      (convx1a): Conv2d(600, 30, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (convx2a): Conv2d(600, 30, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (convx1b): Conv2d(30, 30, kernel_size=(4, 1), stride=(1, 1))\n",
       "      (convx2b): Conv2d(30, 30, kernel_size=(4, 1), stride=(1, 1))\n",
       "      (convx1c): Conv2d(30, 600, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (convx2c): Conv2d(30, 600, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (3): GLUblock(\n",
       "      (convresid): Conv2d(600, 600, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (leftpad): ConstantPad2d(padding=(0, 0, 3, 0), value=0)\n",
       "      (convx1a): Conv2d(600, 30, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (convx2a): Conv2d(600, 30, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (convx1b): Conv2d(30, 30, kernel_size=(4, 1), stride=(1, 1))\n",
       "      (convx2b): Conv2d(30, 30, kernel_size=(4, 1), stride=(1, 1))\n",
       "      (convx1c): Conv2d(30, 600, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (convx2c): Conv2d(30, 600, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (out): AdaptiveLogSoftmaxWithLoss(\n",
       "    (head): Linear(in_features=600, out_features=1128, bias=False)\n",
       "    (tail): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Linear(in_features=600, out_features=150, bias=False)\n",
       "        (1): Linear(in_features=150, out_features=4506, bias=False)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Linear(in_features=600, out_features=37, bias=False)\n",
       "        (1): Linear(in_features=37, out_features=22528, bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0  Batches: 0  Loss: 6.711717128753662\n",
      "Epoch: 0  Batches: 100  Loss: 7.617319583892822\n",
      "Epoch: 0  Batches: 200  Loss: 6.950686931610107\n",
      "Epoch: 0  Batches: 300  Loss: 7.048349857330322\n",
      "Epoch: 0  Batches: 400  Loss: 3.3203938007354736\n",
      "Epoch: 0  Batches: 500  Loss: 5.501758575439453\n",
      "Epoch: 0  Batches: 600  Loss: 4.091529846191406\n",
      "Validation Loss: 6.6916\tPerp: 805.6401\n",
      "Epoch: 1  Batches: 0  Loss: 5.927438259124756\n",
      "Epoch: 1  Batches: 100  Loss: 2.3362200260162354\n",
      "Epoch: 1  Batches: 200  Loss: 5.40895938873291\n",
      "Epoch: 1  Batches: 300  Loss: 4.105952262878418\n",
      "Epoch: 1  Batches: 400  Loss: 5.823309898376465\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "train_loss_list = []; test_loss_list = []\n",
    "for epoch in range(params['epochs']):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        #Si queremos usar GPU hay que pasar los datos a GPU\n",
    "        if params['use_gpu']:\n",
    "            data.cuda()\n",
    "            \n",
    "        #Optimizer\n",
    "        if params['opttype'] == 'sgd':\n",
    "            optimizer = torch.optim.SGD(GCNN.parameters(), lr = params['lr'], momentum=params['mom'], weight_decay=params['wd'],\n",
    "                                       nesterov= params['nesterov'])\n",
    "        elif params['opttype'] == 'adam':\n",
    "            optimizer = torch.optim.Adam(GCNN.parameters(), lr = params['lr'], betas = (params['mom'], 0.999))\n",
    "        \n",
    "        #Dejar los gradientes del optimizador en 0\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        \n",
    "        #Forward pass\n",
    "        output = GCNN(data)\n",
    "        \n",
    "        #Actualizar párametros\n",
    "        loss = output.loss\n",
    "        loss.backward()\n",
    "        \n",
    "        train_loss_list.append(loss.item())\n",
    "        \n",
    "        #Gradient clipping\n",
    "        if params['grad_clip'] != 0:\n",
    "            nn.utils.clip_grad_value_(GCNN.parameters(), params['grad_clip'])\n",
    "            \n",
    "        #Actualizar pesos\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            elapsed_time=time.time()-start_time\n",
    "            print('Epoch: {}  Batches: {}  Loss: {}'.format(epoch, batch_idx, loss.item()))\n",
    "    \n",
    "    #Verificamos ahora en el test set\n",
    "    val_loss=[]\n",
    "    \n",
    "    #Gradientes no se actualizan y modelo en modo evaluacion\n",
    "    with torch.no_grad():\n",
    "        GCNN.eval()\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(test_loader):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            #Forward\n",
    "            output = GCNN(data)\n",
    "            loss = output.loss\n",
    "            output.output\n",
    "            val_loss.append(loss.data.item())\n",
    "        \n",
    "    \n",
    "    #Modelo en modo entrenamiento\n",
    "    GCNN.train()\n",
    "    ave_val_loss=sum(val_loss) / len(val_loss)\n",
    "    val_update_string='Validation Loss: {:.4f}\\tPerp: {:.4f}'.format(ave_val_loss,np.exp(ave_val_loss))\n",
    "    print(val_update_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
